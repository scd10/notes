


# 3 TersorFlow第一步

## 3.2 MNIST手写数字识别
- 10个数字类别转换为d10的**one-hot**编码，这样训练过程中计算特征组合分别在10个类别的概率，再使用softmax把10个类别概率最高的一类抽取出来。
- Numpy是用C和fortan写的，在和python交互中的数据传输效率较低。
- Tensorflow同样也把复杂的运算放到python外边，通过定义一个计算图将所有操作全部运行在python之外，而不需要每次把运算完的数据传回python
- **Variable**用来存储模型参数，在模型迭代过程中是**持久化**的（比如一直放在显存中。
- 对简单模型来说**初始值**不重要，但是对于复杂的网络，**初始化非常重要**，至关重要。
- **Loss Function**越小，代表模型的结果与真实值的偏差越小，也就说明模型越精确。
- 多分类问题通常使用**cross-entropy**作为损失函数，公式如下。其中$y$表示预测值，$y'$表示真实值。

$$H(y) = -\sum_{i}y'_i \log(y_i)$$

- **tf.reduce_mean()**:对batch求均值。
- **tf.reduce_sum()**:求和。

- tesorflow机器学习算法的步骤：
  1. 计算算法公式，也就是forward网络的计算；
  2. 定义Loss，选定优化器，指定优化器优化loss；
  3. 迭代数据进行训练；
  4. 在测试集或验证集上对准确率进行验证。

- Hinton揭示了神经网络的最大价值在于特征的**自动提取和抽象**，免去了人工提取特征的繁琐，可以自动找出复杂且有效的高阶特征。


# 4 Tensorflow实现自编码器及多层感知机

**softplus function**

$$ f(x) = log（1+e^x) $$

其导数，**logistic function**

$$ f'(x) = \frac{e^x}{1+e^x} = \frac{1}{1+e^{-x}}